{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# New import\n",
    "import requests\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data-txn-price-t36.json\"\n",
    "# Change relative file directory to match where the data is\n",
    "data_path = \"././data/\"\n",
    "data_directory = data_path + file_name\n",
    "data = pd.read_json(data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change The Below Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to change for function\n",
    "price_offset_in_days = 0\n",
    "\n",
    "# Prefer that you follow the format \"{Ticker/SPY} Price # {Days/Months/etc} After Txn Date\"\n",
    "ticker_column_name = \"\"\n",
    "spy_column_name = \"\"\n",
    "\n",
    "output_file_name = \"youChange.json\" # need extension \".json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Cell Below to grab the data. This will take ~40 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Transaction Date'] = pd.to_datetime(data['Transaction Date'])\n",
    "data['Ticker'] = data['Ticker'].str.upper()\n",
    "groups = data.groupby('Ticker')\n",
    "bad_tickers = []\n",
    "\n",
    "\n",
    "for ticker, tData in groups:\n",
    "    \n",
    "# test ticker\n",
    "    test_link = f\"https://finance.yahoo.com/quote/{ticker}?p={ticker}&.tsrc=fin-srch\"\n",
    "    val = requests.get(test_link).status_code\n",
    "    if val == 404: # This ticker is invalid, so continue\n",
    "        bad_tickers.append((ticker,\"invalid ticker\"))\n",
    "        continue\n",
    "# alg\n",
    "    try:\n",
    "        min_date = tData['Transaction Date'].min() + datetime.timedelta(days=price_offset_in_days)\n",
    "        max_date = tData['Transaction Date'].max() + datetime.timedelta(days=1+price_offset_in_days)\n",
    "        start_date = str(int(min_date.timestamp()))\n",
    "        end_date = str(int(max_date.timestamp()))\n",
    "    except:\n",
    "        bad_tickers.append((ticker,\"ticker date\"))\n",
    "        continue\n",
    "    \n",
    "    interval = '1d'\n",
    "    event='history'\n",
    "    url = 'https://query1.finance.yahoo.com/v7/finance/download/'      + ticker + '?period1=' + start_date + '&period2=' + end_date + '&interval='      + interval + '&events=' + event\n",
    "    spy_url = 'https://query1.finance.yahoo.com/v7/finance/download/'      + \"SPY\" + '?period1=' + start_date + '&period2=' + end_date + '&interval='      + interval + '&events=' + event\n",
    "    \n",
    "    try:\n",
    "        b_data = pd.read_csv(url)\n",
    "        b_data['Date'] = pd.to_datetime(b_data['Date'])\n",
    "        spy_data = pd.read_csv(spy_url)\n",
    "        spy_data['Date'] = pd.to_datetime(spy_data['Date'])\n",
    "    except:\n",
    "        b_data = []\n",
    "        spy_data = []\n",
    "        bad_tickers.append((ticker,\"data retrieval\"))\n",
    "    # now, get the data from yahoo prices\n",
    "    tData = tData.reset_index()\n",
    "    for i in range(tData.shape[0]):\n",
    "        current_txn_date = tData.loc[i,'Transaction Date']\n",
    "        lower_date = current_txn_date + datetime.timedelta(days=price_offset_in_days) - datetime.timedelta(days=2)\n",
    "        upper_date = current_txn_date + datetime.timedelta(days=2+price_offset_in_days)\n",
    "        try:\n",
    "            b_mask = (b_data['Date'] >= lower_date) & (b_data['Date'] <= upper_date)\n",
    "            spy_mask = (spy_data['Date'] >= lower_date) & (spy_data['Date'] <= upper_date)\n",
    "            data.loc[(data['Transaction Date'] == current_txn_date)&(data['Ticker']==ticker),ticker_column_name] = b_data[b_mask]['High'].mean()\n",
    "            data.loc[(data['Transaction Date'] == current_txn_date)&(data['Ticker']==ticker),spy_column_name] = spy_data[spy_mask]['High'].mean()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = data_path + output_file_name\n",
    "data.to_json(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ca1d37080df844869cb5fbb735530790ceef82057d503d6f46d539fb117aae4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
